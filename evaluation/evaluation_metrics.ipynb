{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6873c9a-2fa8-45cf-9525-0bc0f26e71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pytorch_fid import fid_score\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from scipy.linalg import sqrtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5b65bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_directory(directory, image_size=(299, 299)):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust for your image formats\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = load_img(image_path, target_size=image_size)\n",
    "            img_array = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "            images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "# Load real and generated images\n",
    "real_images_directory = r\"C:\\Users\\kaleem\\Learn\\Wuerth\\thesis\\data\\data_temp\\datasets_temp\\test_set\\generated\\super_impose\\150535_new\"\n",
    "generated_images_directory = r\"C:\\Users\\kaleem\\Learn\\Wuerth\\thesis\\data\\data_temp\\datasets_temp\\test_set\\generated\\super_impose\\150535\"\n",
    "\n",
    "real_images = load_images_from_directory(real_images_directory)\n",
    "generated_images = load_images_from_directory(generated_images_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be39258",
   "metadata": {},
   "source": [
    "### FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aab89832-2b7f-4449-a5c3-a39d7f1c4118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fid_single_image(true_image_path, fake_image_path, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"\n",
    "    Calculate Fr√©chet Inception Distance (FID) between two individual images.\n",
    "\n",
    "    Parameters:\n",
    "    - true_image_path (str): File path of the true image.\n",
    "    - fake_image_path (str): File path of the generated (fake) image.\n",
    "    - device (str): Device to use ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    - fid_score (float): The calculated FID score.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load images and preprocess\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    true_image = Image.open(true_image_path).convert('RGB')\n",
    "    fake_image = Image.open(fake_image_path).convert('RGB')\n",
    "\n",
    "    true_tensor = transform(true_image).unsqueeze(0).to(device)\n",
    "    fake_tensor = transform(fake_image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Calculate FID score\n",
    "    fid_value = fid_score.calculate_fid(true_tensor, fake_tensor, device=torch.device(device))\n",
    "\n",
    "    return fid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64a6e1e6-9e63-4593-85cf-ce88535cadb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 6s 2s/step\n",
      "2/2 [==============================] - 6s 2s/step\n",
      "FID Score: 4.6913032501850305\n"
     ]
    }
   ],
   "source": [
    "def calculate_fid(real_images, generated_images):\n",
    "    # Load InceptionV3 model pre-trained on ImageNet\n",
    "    inception_model = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))\n",
    "\n",
    "    # Preprocess images and get their feature representations\n",
    "    real_features = inception_model.predict(preprocess_input(real_images.astype('float32')))\n",
    "    gen_features = inception_model.predict(preprocess_input(generated_images.astype('float32')))\n",
    "\n",
    "    # Calculate mean and covariance of features\n",
    "    mu1, sigma1 = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n",
    "    mu2, sigma2 = np.mean(gen_features, axis=0), np.cov(gen_features, rowvar=False)\n",
    "\n",
    "    # Calculate FID score\n",
    "    diff = mu1 - mu2\n",
    "    covmean, _ = sqrtm(sigma1 @ sigma2, disp=False)\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "\n",
    "    fid_score = np.sum(diff**2) + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
    "    return fid_score\n",
    "\n",
    "fid_score = calculate_fid(real_images, generated_images)\n",
    "print(\"FID Score:\", fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13a0172c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 299, 299, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefeb35f",
   "metadata": {},
   "source": [
    "### SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e91089e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ssim(real_images, generated_images):\n",
    "    ssim_scores = []\n",
    "\n",
    "    # Loop through each pair of images\n",
    "    for real, generated in zip(real_images, generated_images):\n",
    "        # Ensure images are in the right format (uint8)\n",
    "        real_uint8 = tf.convert_to_tensor(real * 255, dtype=tf.uint8)\n",
    "        generated_uint8 = tf.convert_to_tensor(generated * 255, dtype=tf.uint8)\n",
    "\n",
    "        # Calculate SSIM\n",
    "        score = tf.image.ssim(real_uint8, generated_uint8, max_val=255)\n",
    "        ssim_scores.append(score.numpy())\n",
    "\n",
    "    # Return the average SSIM score\n",
    "    return np.mean(ssim_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c033a703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SSIM Score: 0.06566838\n"
     ]
    }
   ],
   "source": [
    "ssim_score = calculate_ssim(real_images, generated_images)\n",
    "print(\"Average SSIM Score:\", ssim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925a2936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
